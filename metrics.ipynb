{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98640487",
   "metadata": {},
   "source": [
    "## Questionário de Regressão linear, logística, regularização, bias/variância e Métricas de erro\n",
    "### IC - Prof. Rogério\n",
    "\n",
    "#### Marco Túlio S. da Mata 20193007156 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce63310",
   "metadata": {},
   "source": [
    "No que se refere ao gradiente descendente, responda as seguintes questões: \n",
    "\n",
    "a) que teste pode ser feito para sabermos se o gradiente descendente está funcionando \n",
    "corretamente?\n",
    "\n",
    "<span style=\"color:red\">Resposta:</span> Observar a convergencia de valores estáveis para os parametros e a diminuição de erro já que se o algoritmo estiver funcionando como esperado, o valor da função de custo deve diminuir consistentemente em direção a um mínimo.\n",
    "        \n",
    "b) como escolher a taxa de aprendizado do algoritmo gradiente descendente e qual é o seu efeito \n",
    "na convergência? \n",
    "\n",
    "<span style=\"color:red\">Resposta:</span> É crucial para a convergência do gradiente descendente. Se $\\alpha$ for muito grande, o algoritimo pode oscilar ou divergir; por outro lado, se muito pequeno, o processo de convergência será lento podendo durar muitas epocas, sendo um mal uso dos dados. A escolha ideal é geralmente feita por experimentação, observando a convergência em um conjunto de testes, daí vemos os métodos de atualização de parâmetros.\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7626c635",
   "metadata": {},
   "source": [
    "Faça uma comparação e mostre as vantagens e desvantagens de cada um dos seguintes métodos de \n",
    "atualização dos parâmetros de uma regressão: Stochastic Gradient Descent (SGD), Mini-batch e Full \n",
    "Batch.  \n",
    "\n",
    "<span style=\"color:red\">Resposta:</span> \n",
    "\n",
    "*Stochastic Gradient Descent* (SGD): Atualiza os parâmetros com base em um único exemplo por vez. Isso torna o SGD rápido em atualizações, mas a convergência pode ser instável devido à alta variabilidade no cálculo do gradiente. Ele funciona bem em grandes conjuntos de dados.\n",
    "\n",
    "*Mini-batch*: Divide os dados em pequenos lotes e calcula o gradiente com base nesses lotes. Combina a estabilidade do full batch com a eficiência do SGD, oferecendo uma boa convergência e redução no custo computacional.\n",
    "\n",
    "*Full Batch*: Calcula o gradiente com base em todo o conjunto de dados. Embora seja muito estável, é computacionalmente caro e impraticável para conjuntos de dados grandes. É mais usado em pequenos conjuntos de dados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909f4e24",
   "metadata": {},
   "source": [
    "Não sei se vocês observaram, mas na tarefa sobre regressão logística, o sklearn não faz uso do \n",
    "gradiente descendente no ajuste do modelo de regressão, mas sim, utiliza um solver chamado lbfgs. \n",
    "Explique como ele funciona.  \n",
    "\n",
    "<span style=\"color:red\">Resposta:</span> \n",
    "\n",
    "O LBFGS (*Limited-memory Broyden-Fletcher-Goldfarb-Shanno*) é um algoritmo de otimização de segunda ordem que utiliza aproximações da matriz Hessiana (segunda derivada) para melhorar a direção de descida. Ele é mais eficiente que o gradiente descendente em muitos problemas porque não exige uma taxa de aprendizado explícita e geralmente converge mais rápido. No entanto, por usar a aproximação da Hessiana, é mais adequado para conjuntos de dados moderados, onde a memória não é um grande limitante. L-BFGS é considerado \"o algoritmo de escolha\" para ajustar modelos onde sua função de custo é uma combinação de logaritimos lineares (MaxEnt) e campos aleatórios condicionais(logistica) com a regularização L2.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff715efb",
   "metadata": {},
   "source": [
    "Responda as seguintes questões: \n",
    "\n",
    "a. Explique a metodologia usada na escolha do grau de um polinômio de uma determinada hipótese com o propósito de amenizar o problema bias/variância. \n",
    "   \n",
    "<span style=\"color:red\">Resposta:</span>\n",
    "\n",
    "A escolha do grau de um polinômio é feita com base no equilíbrio entre bias e variância. Um grau baixo pode levar a um alto bias (*underfitting*), enquanto um grau alto pode resultar em alta variância (*sobreajuste*). A metodologia comum é usar validação cruzada: avalia-se o desempenho do modelo para diferentes graus do polinômio em dados de validação e seleciona-se aquele que minimiza o erro da função de custo.\n",
    "\n",
    "b. Explique a metodologia usada na escolha do fator de regularização com o propósito de amenizar o problema bias/variância. \n",
    "\n",
    "<span style=\"color:red\">Resposta:</span>\n",
    "\n",
    "O fator de regularização (ex.: λ em Ridge e Lasso) controla a penalização de parâmetros grandes. Valores altos de regularização reduzem a variância ao simplificar o modelo, mas podem aumentar o bias. A escolha do fator ideal também é feita por validação cruzada, testando vários valores de λ para encontrar o melhor equilíbrio."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c19bec2",
   "metadata": {},
   "source": [
    "Por que utilizar a validação cruzada na escolha da melhor hipótese? (obs.: Uma hipótese pode ser um modelo de redes neurais, de árvore de decisão, uma regressão linear etc.)\n",
    "\n",
    "<span style=\"color:red\">Resposta:</span>\n",
    "\n",
    "A validação cruzada é utilizada para escolher a melhor hipótese porque permite avaliar o desempenho do modelo em diferentes subconjuntos dos dados. Isso evita problemas como overfitting em um único conjunto de validação e oferece uma estimativa mais robusta do erro esperado em novos dados. Com isso, a hipótese escolhida tende a generalizar melhor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c898cfca",
   "metadata": {},
   "source": [
    "Suponha que seu algoritmo de aprendizagem não esteja trabalhando de forma adequada, ou seja, o $J_{cv}(\\theta)$ ou $J_{test}(\\theta)$ apresentou valor elevado. Este é um problema de bias ou de variância? \n",
    "Justifique a resposta. \n",
    "\n",
    "<span style=\"color:red\">Resposta:</span>\n",
    "\n",
    "Se o algoritmo apresenta um erro elevado, pode ser um problema de bias ou variância. O problema é de bias quando o modelo subestima a complexidade dos dados (subajuste). Já um erro elevado em dados de teste, com bom desempenho no treino, indica alta variância (sobreajuste). A análise das métricas em diferentes conjuntos de dados ajuda a identificar a causa.\n",
    "\n",
    "Se o erro da função de custo  $J$ for elevado em todos os conjuntos, incluindo \n",
    " $J_{cv}(\\theta)$ e  $J_{test}(\\theta)$, o problema é de bias (subajuste), indicando que o modelo é muito simples para capturar a complexidade dos dados. \n",
    "\n",
    "Já quando o erro de treino $J_{cv}(\\theta)$ é baixo mas $J_{test}(\\theta)$\n",
    "  são elevados, o problema é de variância (sobreajuste), sugerindo que o modelo se ajustou demais aos dados de treinamento, mas generaliza mal. Para bias, pode-se aumentar a complexidade do modelo (ex.: mais características ou maior grau de polinômio); para variância, usar regularização ou mais dados ajuda a reduzir o erro.\n",
    "  \n",
    "  Quando a complexidade do polinômio é próxima da ideal, aumentar os dados auxilia na redução de ruídos e no refinamento da escolha de hiperparâmetros, mas, se o modelo for muito complexo ou muito simples, o impacto será limitado. Em geral, mais dados ajudam a estabilizar as métricas de validação, mas não corrigem limitações estruturais do modelo(como melhor a função custo por um especialista).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ceb5d44",
   "metadata": {},
   "source": [
    "Dado a matrix de confusão: {5 ,2 ,0; 3, 3, 2; 0, 1, 11}, calcule as metricas:\n",
    "\n",
    "a) Acurácia   \n",
    "\n",
    "b) Macro-precison  \n",
    "\n",
    "c) Macro-Recall \n",
    "\n",
    "d) Macro-F1 Score \n",
    "\n",
    "e) Weighted-precision \n",
    "\n",
    "f) Weighted-recall \n",
    "\n",
    "g) Weighted-F1 \n",
    "\n",
    "h) Micro-precison  \n",
    "\n",
    "i) Micro-Recall  \n",
    "\n",
    "j) Micro-F1 Score \n",
    "\n",
    "<span style=\"color:red\">Resposta:</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b63da4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 0.70\n",
      "Macro Precision: 0.66\n",
      "Macro Recall: 0.67\n",
      "Macro F1 Score: 0.66\n",
      "Weighted Precision: 0.69\n",
      "Weighted Recall: 0.70\n",
      "Weighted F1 Score: 0.69\n",
      "Micro Precision: 0.70\n",
      "Micro Recall: 0.70\n",
      "Micro F1 Score: 0.70\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "# Matriz de Confusão\n",
    "conf_matrix = np.array([\n",
    "    [5, 2, 0],  # Classe 0\n",
    "    [3, 3, 2],  # Classe 1\n",
    "    [0, 1, 11]  # Classe 2\n",
    "])\n",
    "\n",
    "# ! código de práticas anteriores !\n",
    "\n",
    "true_counts = [np.sum(conf_matrix[i, :]) for i in range(3)]\n",
    "total_samples = np.sum(conf_matrix)\n",
    "\n",
    "# Acurácia\n",
    "accuracy = np.trace(conf_matrix) / total_samples\n",
    "\n",
    "# Precisão, Recall e F1 Macro\n",
    "true_labels = np.repeat([0, 1, 2], true_counts)\n",
    "predicted_labels = []\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        predicted_labels.extend([j] * conf_matrix[i, j])\n",
    "predicted_labels = np.array(predicted_labels)\n",
    "\n",
    "macro_precision = precision_score(true_labels, predicted_labels, average='macro')\n",
    "macro_recall = recall_score(true_labels, predicted_labels, average='macro')\n",
    "macro_f1 = f1_score(true_labels, predicted_labels, average='macro')\n",
    "\n",
    "# Precisão, Recall e F1 Weighted\n",
    "weighted_precision = precision_score(true_labels, predicted_labels, average='weighted')\n",
    "weighted_recall = recall_score(true_labels, predicted_labels, average='weighted')\n",
    "weighted_f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
    "\n",
    "# Precisão, Recall e F1 Micro\n",
    "micro_precision = precision_score(true_labels, predicted_labels, average='micro')\n",
    "micro_recall = recall_score(true_labels, predicted_labels, average='micro')\n",
    "micro_f1 = f1_score(true_labels, predicted_labels, average='micro')\n",
    "\n",
    "print(f\"Acurácia: {accuracy:.2f}\")\n",
    "print(f\"Macro Precision: {macro_precision:.2f}\")\n",
    "print(f\"Macro Recall: {macro_recall:.2f}\")\n",
    "print(f\"Macro F1 Score: {macro_f1:.2f}\")\n",
    "print(f\"Weighted Precision: {weighted_precision:.2f}\")\n",
    "print(f\"Weighted Recall: {weighted_recall:.2f}\")\n",
    "print(f\"Weighted F1 Score: {weighted_f1:.2f}\")\n",
    "print(f\"Micro Precision: {micro_precision:.2f}\")\n",
    "print(f\"Micro Recall: {micro_recall:.2f}\")\n",
    "print(f\"Micro F1 Score: {micro_f1:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ca58e2",
   "metadata": {},
   "source": [
    "Mostre as principais diferenças das técnicas de regularização L2 (Ridge), L1(Lasso) e indique em quais o uso de cada uma delas seria mais indicado.  \n",
    "\n",
    "<span style=\"color:red\">Resposta:</span>\n",
    "\n",
    "L1 (Lasso): Introduz uma penalização proporcional ao valor absoluto dos coeficientes. Promove a seleção de características ao reduzir alguns coeficientes a zero. Útil em problemas de alta dimensionalidade. Interpretação mais simples (seleção de características).\n",
    "\n",
    "L2 (Ridge): Penaliza o quadrado dos coeficientes, forçando-os a serem pequenos, mas sem zerá-los. É útil para lidar com multicolinearidade. Estabilidade para modelos com muitas variáveis correlacionadas.\n",
    "\n",
    "Extra -> ElasticNet: Combina L1 e L2, sendo útil quando há muitas características correlacionadas.\n",
    "\n",
    "\n",
    "$\n",
    "J_{linear}(\\theta) = \\frac{1}{2m} \\sum_{i=1}^{m} \\left( h_\\theta(x^{(i)}) - y^{(i)} \\right)^2 + \\lambda \\sum_{j=1}^{n} |\\theta_j|\n",
    "$\n",
    "\n",
    "$\n",
    "J_{linear}(\\theta) = \\frac{1}{2m} \\sum_{i=1}^{m} \\left( h_\\theta(x^{(i)}) - y^{(i)} \\right)^2 + \\frac{\\lambda}{2} \\sum_{j=1}^{n} \\theta_j^2\n",
    "$\n",
    "\n",
    "\n",
    "\n",
    "$\n",
    "J_{logistica}(\\theta) = -\\frac{1}{m} \\sum_{i=1}^{m} \\left[ y^{(i)} \\log(h_\\theta(x^{(i)})) + (1 - y^{(i)}) \\log(1 - h_\\theta(x^{(i)})) \\right] + \\lambda \\sum_{j=1}^{n} |\\theta_j|\n",
    "$\n",
    "\n",
    "$\n",
    "J_{logistica}(\\theta) = -\\frac{1}{m} \\sum_{i=1}^{m} \\left[ y^{(i)} \\log(h_\\theta(x^{(i)})) + (1 - y^{(i)}) \\log(1 - h_\\theta(x^{(i)})) \\right] + \\frac{\\lambda}{2} \\sum_{j=1}^{n} \\theta_j^2 $\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
